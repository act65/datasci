{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probably approximately correct\n",
    "\n",
    "what is it missing?\n",
    "\n",
    "`Probably`: given that you have sampled the data, does it contain enough info about the function you want to learn\n",
    "\n",
    "`Approximately`: does your learned fuction achieve epsilon-error?\n",
    "\n",
    "\n",
    "Efficiently, probably, approximately, correct.\n",
    "\n",
    "In practice, we dont care so much about the `probably` part? We can just restart from another init (although, if we have to do hundreds we probably do care...), and hope we sample the data 'better'. This is a result of many real world applications using offline training?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> _For each $n \\ge 1$ let $C_n$ be a set of target concepts over the instance space $\\{0,1\\}^n$, and let $C = \\{C_n\\}_{n \\ge 1}$. Let $H_n$, for $n \\ge 1$, and $H$ be defined similarly. We can define PCA learnability as follows: The concept class $C$ is PCA learnable by the hypothesis space $H$ if there exists a polynomical time learning algorithm $A$ and a polynomial $p(\\cdot,\\cdot,\\cdot)$ such that for all $n \\ge 1$, all target concepts $c \\in C_n$, all probability distributions $D$ on the instance space $\\{0, 1\\}^n$, and all $\\epsilon$ and $\\delta$, where $0 < \\epsilon, \\delta < 1$, if the algorithm $A$ is given at least $p(n, 1/\\epsilon, 1/\\delta)$ indepedent random examples of $c$ drawn according to $D$, then with porbabilty at least $1-\\delta$, $A$ returns a hypothesis $h \\in H_n$ with $error(h) \\le \\epsilon$. The smallest such polynomial $p$ is called the sampled complexity of the learning algorithm $A$._\n",
    "\n",
    "\n",
    "* There is no bound on how much memory, compute is used. __Problem is that these depend of the learning algol used...__\n",
    "* Is it possible to search for A that satisfy this definition? What is the class of all A that can make a problem learnable? What is the size of the class of A that dont learn it (pretty big..)? I guess you could always give A a bunch of prior information...? But what info? How would it actually help? Design a case!! Is PAC PAC learnable?\n",
    "* \n",
    "* It feels weird that there are no assumptions about; smoothness, locality, ... ? What do these buy you? Make a non-PAC learnable now learnable?\n",
    "* The sample complexity is based on all possible target concepts and distributions. So ... worst case ...\n",
    "* It is still possible to do an exponential amount of compute with a polynomial number of samples...\n",
    "* Can we reword this into something more intuitive?\n",
    "* what if you have a noisy/dishonest oracle?\n",
    "* what about if you hypothesis class doesnt contain the target concept?\n",
    "* what if the algol doesnt necessarily find the global minima, a 'constitent' algol, but rather some 'good enough' local minima? Aka what about algols with noise!?\n",
    "\n",
    "> Why is $n$ in there?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Questions\n",
    "\n",
    "* __ How can it be improved to average case?__ Do we even care about average case...? We care about our case, and other similar ones... What occurs in practice...?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# want toy example(s)!? one that is PAC and one that isnt!?\n",
    "# could use something from cryptography? or just reverse engineering DFAs?\n",
    "H = set()\n",
    "C = set()\n",
    "\n",
    "class Learning_Algol():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Resources\n",
    "\n",
    "* https://jeremykun.com/2014/01/02/probably-approximately-correct-a-formal-theory-of-learning/\n",
    "* https://jeremykun.com/2014/04/21/an-un-pac-learnable-problem/\n",
    "\n",
    "Other questions\n",
    "\n",
    "* What about `transferable` (aka generalisable?). A concept in X is transferable to Y if ...?\n",
    "* How can I use an automated proof assistant to help me here?\n",
    "* Lower bounds?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
